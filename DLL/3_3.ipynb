{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprised-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "trained-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(w,b,nums): #@save\n",
    "    X=torch.normal(0,1,(nums,len(w)))\n",
    "    y=torch.mm(X,w)+b\n",
    "    y+=torch.normal(0,0.1,y.shape)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "superior-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=250\n",
    "true_w=torch.tensor([2.,1.]).reshape(2,-1)\n",
    "true_b=torch.tensor([3.])\n",
    "features,labels=data_gen(true_w,true_b,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sought-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterator\n",
    "def iterator(data_array,batchsize,istrain=True):\n",
    "    dataset=data.TensorDataset(*data_array)\n",
    "    # data loader generate an iterater\n",
    "    return data.DataLoader(dataset,batchsize,shuffle=istrain)\n",
    "\n",
    "dataset=iterator([features,labels],batchsize,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "final-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model\n",
    "from torch import nn\n",
    "net=nn.Sequential(nn.Linear(2,1))\n",
    "\n",
    "## fill numbers\n",
    "net[0].weight.data.normal_(0,1)\n",
    "net[0].bias.data.fill_(0)\n",
    "\n",
    "## define loss fun\n",
    "loss=nn.L1Loss(reduction='mean')\n",
    "## optimal method\n",
    "trainer=torch.optim.SGD(net.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "royal-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2666,  0.0065]])\n",
      "tensor([[-0.2667,  0.0711]])\n",
      "tensor([[-0.2784,  0.0957]])\n",
      "tensor([[-0.2015, -0.0496]])\n",
      "tensor([[-0.1891,  0.0323]])\n",
      "tensor([[-0.2488,  0.0284]])\n",
      "tensor([[-0.2314,  0.0385]])\n",
      "tensor([[-0.1671,  0.0527]])\n",
      "tensor([[-0.1709, -0.0527]])\n",
      "tensor([[-0.1957,  0.0330]])\n",
      "tensor([[-0.2384,  0.0386]])\n",
      "tensor([[-0.3239,  0.0856]])\n",
      "tensor([[-0.1906,  0.1304]])\n",
      "tensor([[-0.2669, -0.0655]])\n",
      "tensor([[-0.3095,  0.0274]])\n",
      "tensor([[-0.1774,  0.0521]])\n",
      "tensor([[-0.2363, -0.0019]])\n",
      "tensor([[-0.2162,  0.0638]])\n",
      "tensor([[-0.2443,  0.0852]])\n",
      "tensor([[-0.3620, -0.0303]])\n",
      "tensor([[-0.2884, -0.0151]])\n",
      "tensor([[-0.2697, -0.0304]])\n",
      "tensor([[-0.1664, -0.0467]])\n",
      "tensor([[-0.1876,  0.0094]])\n",
      "tensor([[-0.1582,  0.0466]])\n",
      "tensor([[-0.2411, -0.0146]])\n",
      "tensor([[-0.2056,  0.1099]])\n",
      "tensor([[-0.2042,  0.0301]])\n",
      "tensor([[-0.1663,  0.0463]])\n",
      "tensor([[-0.1629, -0.0691]])\n"
     ]
    }
   ],
   "source": [
    "epoch=30\n",
    "for i in range(epoch):\n",
    "    for X,y in dataset:\n",
    "        l=loss(net(X),y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        print(net[0].weight.grad)\n",
    "        break\n",
    "        trainer.step()\n",
    "#print(net[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "weird-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `torch.nn.Huber` not found.\n"
     ]
    }
   ],
   "source": [
    "?torch.nn.Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "primary-vancouver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Creates a criterion that measures the mean squared error (squared L2 norm) between\n",
       "each element in the input :math:`x` and target :math:`y`.\n",
       "\n",
       "The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
       "\n",
       ".. math::\n",
       "    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
       "    l_n = \\left( x_n - y_n \\right)^2,\n",
       "\n",
       "where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
       "(default ``'mean'``), then:\n",
       "\n",
       ".. math::\n",
       "    \\ell(x, y) =\n",
       "    \\begin{cases}\n",
       "        \\operatorname{mean}(L), &  \\text{if reduction} = \\text{'mean';}\\\\\n",
       "        \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{'sum'.}\n",
       "    \\end{cases}\n",
       "\n",
       ":math:`x` and :math:`y` are tensors of arbitrary shapes with a total\n",
       "of :math:`n` elements each.\n",
       "\n",
       "The mean operation still operates over all the elements, and divides by :math:`n`.\n",
       "\n",
       "The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.\n",
       "\n",
       "Args:\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
       "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
       "        ``'mean'``: the sum of the output will be divided by the number of\n",
       "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
       "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, *)` where :math:`*` means, any number of additional\n",
       "      dimensions\n",
       "    - Target: :math:`(N, *)`, same shape as the input\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> loss = nn.MSELoss()\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.randn(3, 5)\n",
       "    >>> output = loss(input, target)\n",
       "    >>> output.backward()\n",
       "\u001b[1;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-lucas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
