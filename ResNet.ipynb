{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "conv_base = ResNet50(include_top=False, input_shape=(224,224,3)) #模型也可以看作一个层\n",
    "model = Sequential()\n",
    "model.add(conv_base) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冻结之前可训练的张量个数： 216\n",
      "冻结之后可训练的张量个数： 4\n"
     ]
    }
   ],
   "source": [
    "print(\"冻结之前可训练的张量个数：\", len(model.trainable_weights)) #结果为30\n",
    "conv_base.trainable = False\n",
    "print(\"冻结之后可训练的张量个数：\", len(model.trainable_weights)) #结果为4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "16000 16000\n"
     ]
    }
   ],
   "source": [
    "# 数据生成器\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "\tdef __init__(self, filenames, labels, batch_size):\n",
    "\t\tself.filenames = filenames\n",
    "\t\tself.labels = labels\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself._shuffle()\n",
    "\n",
    "\tdef _shuffle(self):\n",
    "\t\tself.indexes = np.arange(len(self.filenames))\n",
    "\t\tnp.random.shuffle(self.indexes)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef _parse(imgPath):\n",
    "\t\txx = np.zeros((224,224,3))\n",
    "\t\timg = Image.open(imgPath)\n",
    "\t\tout = img.resize((224,224))\n",
    "\t\tout = np.array(out)\n",
    "\t\ts = out.shape\n",
    "\t\txx[:224,:,:] = out[:,:,:]\n",
    "\t\t#获取图像频域数据：暂时先*盲目的*只取了通道0做DCT： 先DCT - 再把高度resize成64 - 再做FFT - 最后每行采样250个点\n",
    "\t\t'''\n",
    "\t\timg = cv2.imread(imgPath)\n",
    "\t\timg = img[:,:,0]\n",
    "\t\tif img.shape[0] % 2 == 1:\n",
    "\t\t\timg = img[:img.shape[0]-1,:]\n",
    "\t\tif img.shape[1] % 2 == 1:\n",
    "\t\t\timg = img[:,:img.shape[1]-1]\n",
    "\t\timgdct = cv2.dct(np.float32(img))\n",
    "\t\tif imgdct.shape[1] >= 250:\n",
    "\t\t\timgdct = cv2.resize(imgdct, (imgdct.shape[1],64))\n",
    "\t\telse:\n",
    "\t\t\timgdct = cv2.resize(imgdct, (250,64))\n",
    "\t\tres = np.zeros((64,250))\n",
    "\t\tidx =np.linspace(0,imgdct.shape[1]-1,num=250, dtype=int)\n",
    "\t\t#for i in range(64):\n",
    "\t\t#fftres = fft(imgdct[i,:])\n",
    "\t\t#\tres[i,:] = fftres[idx]\n",
    "\t\t#xx[224:224+64,:125,0] = res[:,:125]\n",
    "\t\t#xx[224:224+64,:125,1] = res[:,125:]\n",
    "\t\t#end\n",
    "\t\t'''        \n",
    "\t\treturn xx\n",
    "\n",
    "\tdef on_epoch_end(self):\n",
    "\t\tself._shuffle()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn math.ceil(len(self.filenames)/float(self.batch_size))\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tbatch_indexes = self.indexes[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "\t\tbatch_x = np.array([self._parse(self.filenames[i]) for i in batch_indexes])\n",
    "\t\tbatch_y = np.array([self.labels[i] for i in batch_indexes])\n",
    "\t\treturn batch_x, batch_y\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "#读取文件名和labels\n",
    "def getFiles(folder, y):\n",
    "\tglobal cnt\n",
    "\tglobal filenames\n",
    "\tglobal labels\n",
    "\troot_path ='E:/LectureFile/datamining/traindata/'+folder+'/'\n",
    "\tdir = root_path\n",
    "\tfor root,dir,files in os.walk(dir):\n",
    "\t\tfor file in files:\n",
    "\t\t\tfname = str(file)\n",
    "\t\t\tif fname[0] == '.':\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timgPath = root_path+fname\n",
    "\t\t\tif imgPath[-4:] != \".gif\":\n",
    "\t\t\t\tif os.path.getsize(imgPath) >= 1024*1024*3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\timg = Image.open(imgPath)\n",
    "\t\t\t\tif img.size[0]*img.size[1] >= 1000*1000:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tout = img.resize((224,224))\n",
    "\t\t\t\tout = np.array(out)\n",
    "\t\t\t\ts = out.shape\n",
    "\t\t\t\tif len(s) != 3 or s[0] != 224 or s[1] != 224 or s[2] != 3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tfilenames.append(imgPath)\n",
    "\t\t\t\tlabels.append(y)\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tif cnt%1000==0:\n",
    "\t\t\t\t\tprint(cnt)\n",
    "\t\t\t\t\tif cnt>=16000:\n",
    "\t\t\t\t\t\tbreak\n",
    "getFiles('rumor_pic',0)\n",
    "getFiles('true_pic_1',1)\n",
    "getFiles('truth_pic_2',1)\n",
    "print(len(filenames),len(labels))\n",
    "\n",
    "#训练前先Shuffle操作一次\n",
    "L = len(filenames)\n",
    "idx = np.array(list(range(L)))\n",
    "np.random.shuffle(idx)\n",
    "n_filenames = []\n",
    "n_labels = []\n",
    "for i in range(len(idx)):\n",
    "\tn_filenames.append(filenames[idx[i]])\n",
    "\tn_labels.append(labels[idx[i]])\n",
    "filenames = n_filenames\n",
    "labels = n_labels\n",
    "\n",
    "#数据生成器，80%训练，20%测试\n",
    "train_gen = DataGenerator(filenames[:int(0.8*L)], labels[:int(0.8*L)], 32)\n",
    "test_gen  = DataGenerator(filenames[int(0.8*L):], labels[int(0.8*L):], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 604s 24s/step - loss: 7.4175 - accuracy: 0.5163 - val_loss: 7.4941 - val_accuracy: 0.5113\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(train_gen, \n",
    "                       steps_per_epoch=500/20,\n",
    "                       epochs=1,\n",
    "                       validation_data=test_gen,\n",
    "                       validation_steps=1000/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取图片并生成一个输入数据\n",
    "def read_data(imgPath):\n",
    "\tifread = True\n",
    "\tif ifread:\n",
    "\t\timgs = cv2.imread(imgPath)\n",
    "\t\tout = np.zeros((224,224,3))\n",
    "\t\tfor i in range(3):\n",
    "\t\t\timg = imgs[:,:,i]\n",
    "\n",
    "\t\t\t#====== 选择像素域作为输入 ======\n",
    "\t\t\timgdct = cv2.resize(img, (224,224))\n",
    "\n",
    "\t\t\t#====== 选择离散余弦变换作为输入 ======\n",
    "\t\t\t'''if img.shape[0] % 2 == 1:\n",
    "\t\t\t\timg = img[:img.shape[0]-1,:]\n",
    "\t\t\tif img.shape[1] % 2 == 1:\n",
    "\t\t\t\timg = img[:,:img.shape[1]-1]\n",
    "\t\t\timgdct = cv2.resize(cv2.dct(np.float32(img)), (128,128))\n",
    "\n",
    "\t\t\t#====== 选择傅立叶变换作为输入 ======\n",
    "\t\t\t#imgdct = cv2.resize(np.real(fft(img)), (128,128))'''\n",
    "\n",
    "\t\t\tout[:,:,i] = imgdct\n",
    "\t\tout = out.flatten()\n",
    "\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseData(count,start):\n",
    "\ttot = 0\n",
    "\tcx = []\n",
    "\tcy = []\n",
    "\tprint(len(filenames))    \n",
    "\tfor i in range(start, len(filenames)):\n",
    "\t\tcx.append(read_data(filenames[i]))\n",
    "\t\tcy.append(labels[i])\n",
    "\t\ttot += 1\n",
    "\t\tif tot % 1000 == 0:\n",
    "\t\t\tprint(tot)\n",
    "\t\tif tot == count:\n",
    "\t\t\tbreak\n",
    "\tcx = np.array(cx)\n",
    "\tcy = np.array(cy)\n",
    "\treturn cx,cy,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading testing data ...\n",
      "8000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "(4000, 150528) (4000,)\n",
      "Scanned Testing Sample: 4000 ( Actual testing size: 4000 )\n"
     ]
    }
   ],
   "source": [
    "#获得测试数据\n",
    "print(\"Start reading testing data ...\")\n",
    "test_x, test_y, last = chooseData(12000, 4000)\n",
    "print(test_x.shape, test_y.shape)\n",
    "N_test = test_y.shape[0]\n",
    "print(\"Scanned Testing Sample:\", N_test, '( Actual testing size:', test_y.shape[0], ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting ...\n",
      "Testing Acc: 3915.0\n"
     ]
    }
   ],
   "source": [
    "test_x.resize((4000,224,224,3))\n",
    "print(\"Start predicting ...\")\n",
    "pred_y = model.predict(test_x)\n",
    "test_acc = (np.sum(pred_y == test_y)) / N_test\n",
    "print(\"Testing Acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(N_test)\n",
    "print(np.sum(pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.resize(4000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (np.sum(pred_y == test_y)) / N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97875\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
